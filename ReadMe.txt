
    Чтение файлов большого объема:

    using (var streamReader = new StreamReader(fileName)) //построчное чтение
    {
        string line;
        while ((line = streamReader.ReadLine()) != null)
        {
            // analize line here
            // throw it away if it does not match
        }
    }
	
            foreach (string l in File.ReadLines(path, Encoding.GetEncoding(1251)))
                http://www.cyberforum.ru/csharp-beginners/thread757831.html


    В CLR лимит на один объекта -2 GB, даже в 64 - х битной.
    Можно написать свою обертку, которая будет выделять кусками, а наружу выглядеть почти как обычный массив.
    BigArray<T>, getting around the 2GB array size limit
     В 4.5 можно убрать это ограничение для 64-х битной CLR - gcAllowVeryLargeObjects
     http://msdn.microsoft.com/en-us/library/hh285054(v=vs.110).aspx






    



1. При работе с файловой системой практически бесполезно самому параллелить компрессию.
	Скорее всего скорость упрется в скорость диска.
    Необходимо чтобы сам алгоритм занимался этим.Стандартный GZipStream такого не умеет.
2. Но, можно попрбовать воспользоваться сторонними библиотеками - http://stackoverflow.com/questions/5901225/is-it-safe-to-call-icsharpcode-sharpziplib-in-parallel-on-multiple-threads
    Выполняйте компрессию в MemoryStream, когда закончите сбрасывайте на диск.
	Тогда не упретесь в скорость диска и сможете параллельность использовать.
3. Начать следует с грамотного (строчного, блочного и\или многопоточного) прочтения огромадного файла.
    Остальное приложиться - потоки, очереди, сжатие.



    1. Создаем объект для хранения сжатых данных, с обязательным наличие ключа.
    2. Запускаем чтение файла, после чтения N количества данных стартуем первый поток обработки.И так по кругу, в несколько потоков.
    3. Если свободных поток нет, ждем когда появится первый свободный и ему скармливаем очередную порцию.
    4. Создаем глобальный счетчик, лучше volatile. 
	   В каждом потоке обработки после обработки очередного блока устанавливаем наш ключ объекта хранения (этим счетчиком) и увеличиваем его на 1.
    5. Записываем наш блок в хранилище блоков сжатых данных(словарь или что-то подобное).
    6. После окончания сжатия сортируем получившееся хранилище по ключу, и в итоге мы получим все блоки в том порядке, в каком они были сжаты.
    Вот примерный алгоритм, как я его вижу.
    как нужно выбирать размер памяти, отведенный приложению?
    Думаю, это можно оставить на усмотрение CLR.



	   создание потока на чтение файла по байтам, блоками ? 
       сохраннеие блоков в памяти
       применение многопоточного сжатия для каждого блока
       прогресс сжатия (сначала примитивно в процентах)
       создание потока на запись нового файла *.gz



	
	https://social.msdn.microsoft.com/Forums/en-US/70784fe4-2b89-4d58-ae05-38bff94c3006/how-to-read-big-text-files-in-c-threads?forum=csharplanguage
	http://stackoverflow.com/questions/26010915/unbuffered-output-very-slow

	http://stackoverflow.com/questions/2161895/reading-large-text-files-with-streams-in-c-sharp

	using (FileStream fs = File.Open(path, FileMode.Open, FileAccess.Read, FileShare.ReadWrite))
    using (BufferedStream bs = new BufferedStream(fs))
    using (StreamReader sr = new StreamReader(bs))
    {
		string line;
		while ((line = sr.ReadLine()) != null)
		{

		}
	}







  



Решение пункта 2
###################################################################################################################################################
http://stackoverflow.com/questions/155610/how-do-i-specify-the-exit-code-of-a-console-application-in-net

int main(string[] args)
{
      return 0; //or exit code of your choice
}


enum ExitCode : int {
  Success = 0,
  InvalidLogin = 1,
  InvalidFilename = 2,
  UnknownError = 10
}

int Main(string[] args) {
   return (int)ExitCode.Success;
}

//=============================================
int code = 5;
Environment.Exit(code);
//=============================================

[Flags]
enum ExitCodes : int
{
  Success = 0,
  SignToolNotInPath = 1,
  AssemblyDirectoryBad = 2,
  PFXFilePathBad = 4,
  PasswordMissing = 8,
  SignFailed = 16,
  UnknownError = 32
}

Then
(ExitCodes.SignFailed | ExitCodes.UnknownError)

https://msdn.microsoft.com/ru-ru/library/system.environment.exitcode.aspx
Environment.ExitCode 
Для информации: https://social.msdn.microsoft.com/Forums/vstudio/en-US/707e9ae1-a53f-4918-8ac4-62a1eddb3c4a/detecting-console-application-exit-in-c?forum=csharpgeneral
###################################################################################################################################################





Решение пункта 1.2
###################################################################################################################################################
        // stackoverflow.com/questions/14422773/decompress-a-gz-file-using-gzipstream
		       // www.dotnetperls.com/decompress



			   
###################################################################################################################################################

Выравнивание по размеру кластера.
Каждый раз, когда происходит чтение или запись в файл с диска, то это происходит большими кусками, даже если вам нужен всего один байт. Так устроено, что минимальная физическая единица записи/чтения называется «сектор», стандартный размер которого 512 байт. Но при выборе файловой системы используется единица «кластер», размер которой кратен размеру сектора. При установке Windows, стандартный размер кластера – 4 KiB. Это значит, что если у вас есть файл размером 1 байт, то физически он будет занимать весь кластер. Соответственно при чтении/записи операционная система будет оперировать кластерами.
Из этого следует, что если записать в файл последовательно 2 KiB данных, а потом ещё 1 KiB, то на диск будет записано 4 KiB в первый раз, а потом 4 KiB второй раз. Чтобы избежать такой двойной записи в один и тот же кластер, достаточно объединить данные и скинуть их на диск за один раз. Также, если вы пытаетесь записать 2 KiB с позиции в файле 3 KiB, то первый KiB пойдёт в первый кластер, а второй KiB будет записан уже во второй кластер.
Похожая ситуация происходит при чтении. Если вы читаете сколь-угодно байт из файла, то будет прочитан весь кластер, а если данные пересекают границу двух кластеров – то два кластера. Хотя, стоит учесть, что все жёсткие диски и RAID контроллеры имеют внутренний кэш, который может существенно ускорить чтение и запись секторов.
Для избегания повторных операций чтения/записи, всегда оперируйте последовательными блоками памяти, размером в кластер. В этом поможет обычный класс FileStream, однако размер его внутреннего буфера по-умолчанию жёстко установлен в 4 KiB. Просто получите размер кластера, и передайте его в конструктор FileStream в качестве переменной bufferSize.

Пример кода получения размера кластера

[DllImport("kernel32.dll", CharSet = CharSet.Unicode, SetLastError = true, EntryPoint = "GetDiskFreeSpaceW")]
static extern bool GetDiskFreeSpace(string lpRootPathName, out int lpSectorsPerCluster, out int lpBytesPerSector, out int lpNumberOfFreeClusters, out int lpTotalNumberOfClusters);

// Each partition has its own cluster size.
public static int GetClusterSize(string path) {

	int sectorsPerCluster;
	int bytesPerSector;
	int freeClusters;
	int totalClusters;
	int clusterSize = 0;
	if (GetDiskFreeSpace(Path.GetPathRoot(path), out sectorsPerCluster, out bytesPerSector, out freeClusters, out totalClusters))
		clusterSize = bytesPerSector * sectorsPerCluster;
	return clusterSize;
}

В сетевых протоколах передачи данных используется термин MTU (Maximum Transmission Unit) для определения размера блока данных для передачи. Но ситуация обстоит несколько сложней и остаётся для самостоятельного изучения.



###################################################################################################################################################


Применяя глобальную обработку исключений 
(Application_Error в ASP.NET, Application.DispatcherUnhandledException в WPF, Application.ThreadException в WinForms и т.д.) важно помнить, 
что при таком подходе мы сможем «ловить» исключительные ситуации, которые произошли ТОЛЬКО в UI потоке, 
то есть мы не «поймаем» исключения из дополнительных фоновых потоков. 
Также мы можем воспользоваться AppDomain.CurrentDomain.UnhandledException и вклиниться в процесс обработки всех необработанных исключительных ситуаций в рамках домена приложения, но мы никак не сможем воспрепятствовать процессу завершения приложения.

Потоки — это дорогостоящие объекты, которые занимают память, могут использовать различные ресурсы системы и находиться в разных состояниях. 
Для их создания требуется время. В сравнении с процессами они менее ресурсоемки, но все же требуют довольно больших затрат на создание и уничтожение. 
Более того, за освобождение занимаемых конкретным потоком ресурсов отвечает разработчик. 
Например, для выполнения массы небольших задач неэффективно запускать множество потоков, так как издержки на их запуск могут превысить выгоду от использования. 
Для того, чтобы иметь возможность повторно использовать уже запущенные потоки и избавиться от издержек на создание, был введен так называемый пул-потоков (ThreadPool). 














==============================================================================================================================

ТРЕБОВАНИЯ!
Написать программу на C#, предназначенную для архивации и разархивации файлов с помощью System.IO.Compression.GzipStream.
Параметры программы, имена исходного и результирующего файлов задаются в командной строке следующим образом:
1.1.	•	для архивации: GZipTest.exe compress [имя исходного файла] [имя архива]
1.2.	•	для разархивации: GZipTest.exe decompress  [имя архива] [имя распакованного файла]
2.	В случае успеха программа возвращает 0, при ошибке  1.
3.	Программа должна эффективно распараллеливать и синхронизировать задачи в многопроцессорной среде
4.	Программа должна обрабатывать файлы, размер которых превышает объем доступной оперативной памяти.
5.	Код должен корректно обрабатывать все исключения
6.	При работе с потоками допускается использовать только стандартные классы и библиотеки из .Net 3.5 
	(исключая ThreadPool, BackgroundWorker, TPL). Ожидается реализация с использованием Thread-ов.
7.	Код программы должен следовать принципам ООП и ООД (читаемость, разбиение на классы и т.д.).
8.	Алгоритм работы программы необходимо описать словами.
9.	Исходники необходимо прислать вместе с проектом Visual Studio.
10.	Дополнительным плюсом будет возможность корректной(!) остановки программы по Ctrl-C.
11.	Время выполнения программы раза в 1.5-2 больше, чем у лучших решений – следствие того, 
	что чтение, компрессия и запись для каждого потока выполняются фактически синхронно. 
	Т.е. пока не будут обработаны и записаны предыдущие блоки, не будут зачитываться и обрабатываться следующие блоки. 
	Кроме этого, можно избежать лишних накладных расходов, создав определенное количество потоков 
	(в данном случае количество выбрано верно – по количеству ядер), и, используя механизмы синхронизации, использовать их повторно.
12.	Отсутствие обработки ошибок в функциях потоков может приводить к падению программы.
13.	Стоит подумать над ООП. 
14. Кроме этого, для лучшей читаемости каждый класс имеет смысл вынести в отдельный файл.


ОЦЕНКА!
Программа будет оцениваться по следующим критериям:
1. Работоспособность – проверяется на тестовых файлах с размерами от 0 до 32 Gb
2. Правильность выбора алгоритма с точки зрения эффективности – должен быть максимально загружен самый слабый компонент системы (диск/процессор)
3. Знание и умение использовать примитивы синхронизации – должны быть правильно выбраны примитивы для синхронизации потоков, доступа к данным
4. Проработка архитектуры – есть разбиение на классы по принципам ООП и ООД, не должно быть лишних классов, интерфейсов, методов и т.д.
5. Читабельность и понятность кода – код должен быть простым, аккуратным; алгоритм программы должен быть понятен без отладки
6. Грамотная обработка ошибок и нестандартных ситуаций – должна выводиться диагностическая информация, по которой должно быть понятно что произошло без отладки программы.
7. Правильное управления ресурсами – не должно быть утечек неуправляемых ресурсов, а также своевременное уничтожение управляемых ресурсов


