
    Чтение файлов большого объема:

    using (var streamReader = new StreamReader(fileName))
    {
        string line;
        while ((line = streamReader.ReadLine()) != null)
        {
            // analize line here
            // throw it away if it does not match
        }
    }
	
            foreach (string l in File.ReadLines(path, Encoding.GetEncoding(1251)))
                http://www.cyberforum.ru/csharp-beginners/thread757831.html


    В CLR лимит на один объекта -2 GB, даже в 64 - х битной.
    Можно написать свою обертку, которая будет выделять кусками, а наружу выглядеть почти как обычный массив.
    BigArray<T>, getting around the 2GB array size limit
     В 4.5 можно убрать это ограничение для 64-х битной CLR - gcAllowVeryLargeObjects
     http://msdn.microsoft.com/en-us/library/hh285054(v=vs.110).aspx






    



1. При работе с файловой системой практически бесполезно самому параллелить компрессию.
	Скорее всего скорость упрется в скорость диска.
    Необходимо чтобы сам алгоритм занимался этим.Стандартный GZipStream такого не умеет.
2. Но, можно попрбовать воспользоваться сторонними библиотеками - http://stackoverflow.com/questions/5901225/is-it-safe-to-call-icsharpcode-sharpziplib-in-parallel-on-multiple-threads
    Выполняйте компрессию в MemoryStream, когда закончите сбрасывайте на диск.
	Тогда не упретесь в скорость диска и сможете параллельность использовать.
3. Начать следует с грамотного (строчного, блочного и\или многопоточного) прочтения огромадного файла.
    Остальное приложиться - потоки, очереди, сжатие.



    1. Создаем объект для хранения сжатых данных, с обязательным наличие ключа.
    2. Запускаем чтение файла, после чтения N количества данных стартуем первый поток обработки.И так по кругу, в несколько потоков.
    3. Если свободных поток нет, ждем когда появится первый свободный и ему скармливаем очередную порцию.
    4. Создаем глобальный счетчик, лучше volatile, и в каждом потоке обработки после обработки очередного блока устанавливаем наш ключ объекта хранения (этим счетчиком) и увеличиваем его на 1.
    5. Записываем наш блок в хранилище блоков сжатых данных(словарь или что-то подобное).
    6. После окончания сжатия сортируем получившееся хранилище по ключу, и в итоге мы получим все блоки в том порядке, в каком они были сжаты.
    Вот примерный алгоритм, как я его вижу.
    как нужно выбирать размер памяти, отведенный приложению?
    Думаю, это можно оставить на усмотрение CLR.



	









==============================================================================================================================
Требования

Написать программу на C#, предназначенную для сжатия и расжатия файлов с помощью System.IO.Compression.GzipStream.
Параметры программы, имена исходного и результирующего файлов задаются в командной строке следующим образом:
•	для архивации: GZipTest.exe compress [имя исходного файла] [имя архива]
•	для разархивации: GZipTest.exe decompress  [имя архива] [имя распакованного файла]
В случае успеха программа возвращает 0, при ошибке  1.

- Программа должна эффективно распараллеливать и синхронизировать задачи в многопроцессорной среде и уметь обрабатывать файлы, 
	размер которых превышает объем доступной оперативной памяти.
- Код должен корректно обрабатывать все исключения, а при работе с потоками допускается использовать только стандартные классы и библиотеки из .Net 3.5 
	(исключая ThreadPool, BackgroundWorker, TPL). Ожидается реализация с использованием Thread-ов.
- Код программы должен следовать принципам ООП и ООД (читаемость, разбиение на классы и тд).
- Алгоритм работы программы необходимо описать словами.
- Исходники необходимо прислать вместе с проектом Visual Studio.
- Дополнительным плюсом будет возможность корректной остановки программы по Ctrl-C.

Программа будет оцениваться по следующим критериям:
1.         Работоспособность – проверяется на тестовых файлах с размерами от 0 до 32 Gb
2.         Правильность выбора алгоритма с точки зрения эффективности – должен быть максимально загружен самый слабый компонент системы (диск/процессор)
3.         Знание и умение использовать примитивы синхронизации – должны быть правильно выбраны примитивы для синхронизации потоков, доступа к данным
4.         Проработка архитектуры – есть разбиение на классы по принципам ООП и ООД, не должно быть лишних классов, интерфейсов, методов и т.д.
5.         Читабельность и понятность кода – код должен быть простым, аккуратным; алгоритм программы должен быть понятен без отладки
6.         Грамотная обработка ошибок и нестандартных ситуаций – должна выводиться диагностическая информация, по которой должно быть понятно что произошло без отладки программы.
7.         Правильное управления ресурсами – не должно быть утечек неуправляемых ресурсов, а также своевременное уничтожение управляемых ресурсов


